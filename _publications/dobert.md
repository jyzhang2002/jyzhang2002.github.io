---
title: "Do BERT-Like Bidirectional Models Still Perform Better on Text Classification in the Era of LLMs?"
collection: publications
permalink: /publication/dobert-llm-textcls
date: 2025-01-01
venue: "Findings of EMNLP 2025"
paperurl: "https://arxiv.org/abs/xxxx.xxxxx"
excerpt: "[Text Classification, BERT, LLM] TL;DR: We comprehensively compare BERT-like bidirectional models and LLM-based methods on various text classification tasks, showing BERT models remain more robust on some tasks."
# header:
#   teaser: /images/publications/dobert.png
---

